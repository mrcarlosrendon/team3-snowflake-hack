{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e71fe5c-90ee-4e75-974b-9037f0a25928",
   "metadata": {
    "collapsed": false,
    "name": "Analyse_location_data_snowflake"
   },
   "source": [
    "# ANALYSE LOCATION DATA IN SNOWFLAKE\n",
    "This notebook will take you through how you can use location data to perform spatial calculations, joins, and visualise the data using the popular **Pydeck** python package.  We will be using the freely available data on the market place provided by **Ordnance Survey** and buildings data provided by **Carto Overture Maps**. \n",
    "\n",
    "## Datasets needed to complete this notebook\n",
    "\n",
    "#### All datasets are available on the Snowflake Marketplace\n",
    "\n",
    "- Ordnance Survey - Urban Extents for Cities, Towns and Vilages\n",
    "- Ordnance Survey - Postcodes, Place Names and Road Numbers\n",
    "- Ordnance Survey - Road Network Great Britain - Open Roads\n",
    "- Ordnance Survey - Unique Property Reference Numbers - Great Britain: Open UPRN\n",
    "- Carto - Overture Maps Buildings\n",
    "\n",
    "Please run the next cell to begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": true,
    "language": "python",
    "name": "import_libraries"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from snowflake.snowpark.functions import *\n",
    "from snowflake.snowpark.types import *\n",
    "import pydeck as pdk\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891bd679-bd76-4040-9d5c-ef5c053bd16a",
   "metadata": {
    "collapsed": false,
    "name": "GEOGRAPHY_GEOMETRY"
   },
   "source": [
    "### 1. GEOJSON DATA FORMATS\n",
    "Snowflake can store and interpolate between the following data formats: \n",
    "\n",
    "-   **GeoJSON**:\n",
    "```json\n",
    "{   \"coordinates\": [     -7.390351649999999e+01,     4.074499730000000e+01   ],   \"type\": \"Point\" }\n",
    "\n",
    "```\n",
    "-   **WKT (Well Known Text)**\n",
    "```text\n",
    "POINT(52.3418 2.2776)\n",
    "```\n",
    "-   **WKB (Well Known Binary)**\n",
    "\n",
    "```binary\n",
    "1,1,0,0,0,235,226,54,26,192,43,74,64,241,244,74,89,134,56,2,64\n",
    "```\n",
    "\n",
    "You can decide how you would like the data to be stored and can interchange between them using the following functions: \n",
    "\n",
    "- **ST_WKT**, \n",
    "- **ST_ASWKB**\n",
    "- **ST_ASGEOJSON**.  \n",
    "\n",
    "You can also store this as planar (Euclidean, Cartesian) coordinate system using an SRID of your choice.\n",
    "\n",
    "Run the **SQL Cell** below to see how these functions work in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10109b8-49d1-4b77-b342-a2ea0a4898df",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "load_table_different_formats"
   },
   "outputs": [],
   "source": [
    "SELECT GEOGRAPHY, ST_ASWKT(GEOGRAPHY), ST_ASWKB(GEOGRAPHY), ST_ASGEOJSON(GEOGRAPHY) FROM POSTCODES_PLACE_NAMES_AND_ROAD_NUMBERS__GREAT_BRITAIN_OPEN_NAMES.PRS_OPEN_NAMES_SCH.PRS_OPEN_NAMES_TBL LIMIT 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536b9b46-345b-4985-a3ba-e50efd43f3db",
   "metadata": {
    "collapsed": false,
    "name": "h_transform"
   },
   "source": [
    "##### GEOGRAPHY AND GEOMETRY\n",
    "\n",
    "- **GEOGRAPHY** - The Geography column models the earth as though it were a perfect sphere and follows the WGS 84 standard.\n",
    "\n",
    "- **GEOMETRY** - The GEOMETRY data type represents features in a planar (Euclidean, Cartesian) coordinate system. The units of the X and Y are determined by the spatial reference system (SRS) associated with the GEOMETRY object. The spatial reference system is identified by the spatial reference system identifier (SRID) number.  Snowflake supports the transformation between systems using the **ST_TRANSFORM**  function.\n",
    "\n",
    "Run the **Python Cell** below to see the difference between GEOGRAPHY AND GEOMETERY.  You will also find out how 'ST_TRANSFORM' works.   The python cell intrduces **Snowpark Data Frames**.  All SQL functions (both user defined and native) are available in both SQL and Python environments.  This Example is using how you can convert from geography to geometry as well as converting between two grid systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3b6f05-a33c-4f7b-849b-bd29a3cc0715",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "transform"
   },
   "outputs": [],
   "source": [
    "names = session.table('POSTCODES_PLACE_NAMES_AND_ROAD_NUMBERS__GREAT_BRITAIN_OPEN_NAMES.PRS_OPEN_NAMES_SCH.PRS_OPEN_NAMES_TBL')\n",
    "names.select('NAME1','GEOGRAPHY')\n",
    "names.limit(5).select('NAME1','GEOGRAPHY',call_function('ST_TRANSFORM',to_geometry('GEOGRAPHY'),4326,27700).alias('GEOMETRY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba85284-706c-41b2-b738-4a4fc9d432b9",
   "metadata": {
    "collapsed": false,
    "name": "heading_sql"
   },
   "source": [
    "As previously stated before, you can interchange between python and sql without losing functionality.\n",
    "\n",
    "Run the cell below to view the same results, this time in SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175748cd-9d11-481e-a277-0c7655ee5378",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "transform_sql"
   },
   "outputs": [],
   "source": [
    "SELECT NAME1,GEOGRAPHY, ST_TRANSFORM(TO_GEOMETRY(GEOGRAPHY),4326,27700) GEOMETRY FROM (\n",
    "select * from POSTCODES_PLACE_NAMES_AND_ROAD_NUMBERS__GREAT_BRITAIN_OPEN_NAMES.PRS_OPEN_NAMES_SCH.PRS_OPEN_NAMES_TBL limit 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5666a7d1-7b5e-4241-a2e3-cb4088fe8278",
   "metadata": {
    "collapsed": false,
    "name": "wkt_wkb"
   },
   "source": [
    "And the geography can be rendered in formats such as WKT and WKB as well.  WKT is an easy format to read - look at the difference between the WKT for the geography column vs the Geometry Column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53b42b7-cbda-4dd4-9ae0-e49f57e81abb",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "wkt_wkb_bng"
   },
   "outputs": [],
   "source": [
    "select \n",
    "TO_GEOGRAPHY(GEOGRAPHY) GEO,\n",
    "ST_ASWKT(GEO) WKT_GEOGRAPHY,\n",
    "ST_ASWKT(TO_GEOMETRY(GEOMETRY)) WKT_GEOMETRY_BNG\n",
    "\n",
    "\n",
    "FROM {{transform_sql}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c86836-a123-4410-bdbe-64b16c1ef726",
   "metadata": {
    "collapsed": false,
    "name": "h_points_polygons"
   },
   "source": [
    "# 2 - Points line Strings and Polygons\n",
    "Snowflake Supports Points, Linestrings and Polygons for both **Geography** and **Geometry** Data Types.  Let's have a look at these in isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8257fcbf-0027-413a-a438-a6bd68467917",
   "metadata": {
    "collapsed": false,
    "name": "_2a_points"
   },
   "source": [
    "## 2a. Looking at Points\n",
    "\n",
    "The dataset you have been looking at briefly consist of millions of points - each reference a place somewhere in the United Kingdom. The Geography format would always contain a **Longitude** for each X and **Latitude** for each Y coordinate inside every point  The Geometry format using the British National Grid would also contain an **Eastings** for each X and **Northings** for each Y coordinate inside every point.\n",
    "\n",
    "It is easy to extract the coordinates from the point by using the functions **ST_X** and **ST_Y**.  Visualisation tools such as **st.map** and **pydeck** require the Latitude and Longitude rather than the point itself - however, you may want to retain the Geography column for other geospatial calculations.  Snowflake supports many geospatial calculations.\n",
    "\n",
    "\n",
    "Below, you are instantly looking at a sample of points from the **Ordnance Survey** Names table.  The simplest map to render is using the built in streamlit module (**st.map**).  This, however as limitations.  For the rest of the lab you will be leveraging **pydeck**.  You will note that the data has been filtered based on the 'type' of point. \n",
    "\n",
    "Below filters the dataset using a Streamlit select box (**st.selectbox**).  All of the visualisations you will see in this lab will be referencing the Latitude and Longitude coordinate system (**WGS 84 or  SRID 4326**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7761f6bd-2a7c-49c2-8a48-bf21f6182ecb",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "looking_at_places"
   },
   "outputs": [],
   "source": [
    "names = session.table('POSTCODES_PLACE_NAMES_AND_ROAD_NUMBERS__GREAT_BRITAIN_OPEN_NAMES.PRS_OPEN_NAMES_SCH.PRS_OPEN_NAMES_TBL')\n",
    "types = names.select('TYPE').distinct()\n",
    "selectedtypes = st.selectbox('Select Type',types)\n",
    "names = names.with_column('LAT',call_function('ST_Y',col('GEOGRAPHY')))\n",
    "names = names.with_column('LON',call_function('ST_X',col('GEOGRAPHY')))\n",
    "namesf = names.filter(col('TYPE')==selectedtypes)\n",
    "\n",
    "r_names = namesf.sample(0.1).limit(1000)\n",
    "\n",
    "st.map(r_names.to_pandas())\n",
    "st.markdown('Here is the data coming from the snowflake dataframe.  the  **GEOGRAPHY** field can be used for a variety of geo based calculations')\n",
    "st.dataframe(r_names.select('NAME1','GEOGRAPHY','LAT','LON'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82efa5d7-cce4-47d1-bac5-a8c5176e3308",
   "metadata": {
    "collapsed": false,
    "name": "head_makepoint"
   },
   "source": [
    "If you need to create a point from Latitude and Longitude, use the **ST_MAKEPOINT** to combine LAT and LON to a geography point, or **ST_MAKEGEOPOINT** to convert X and Y to a geometry point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e62199d-1afd-4e40-8ba7-11acaae51dc8",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "example_makepoint"
   },
   "outputs": [],
   "source": [
    "r_names.select(call_function('ST_MAKEPOINT',col('LON'),col('LAT')).alias('POINT')).limit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdd984f-f054-43a5-9390-55c8b1e5d772",
   "metadata": {
    "collapsed": false,
    "name": "select_relevent_columns"
   },
   "source": [
    "Lets select the fields within the dataset that we want to use.  We are referencing the previously created **Snowpark Dataframe**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874b986b-d97e-4c9e-acb2-23c53633c366",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "select_the_fields_we_want"
   },
   "outputs": [],
   "source": [
    "snames = names.select('NAME1',\n",
    "                      'NAME2',\n",
    "                      'NAME2_LANG',\n",
    "                      'TYPE',\n",
    "                      'LOCAL_TYPE',\n",
    "                      'POSTCODE_DISTRICT',\n",
    "                      'POPULATED_PLACE',\n",
    "                      'DISTRICT_BOROUGH',\n",
    "                      'COUNTY_UNITARY',\n",
    "                      'REGION',\n",
    "                      'LAT',\n",
    "                      'LON',\n",
    "                      'GEOGRAPHY')\n",
    "snames.limit(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a5f9b2-9304-43a2-9193-61e334723a6d",
   "metadata": {
    "collapsed": false,
    "name": "pydeck_intro"
   },
   "source": [
    "##### Using Pydeck to visualise the results\n",
    "\n",
    "Here, I have decided to use Pydeck to visualise the results because it has a lot more flexibility than st.map such as: \n",
    "\n",
    "- creating tooltips, \n",
    "\n",
    "- rendering multi layer maps\n",
    "\n",
    "- rendering points, linestrings, polygons and H3 cells\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For this first map I will take you through each part of the code step by step\n",
    "\n",
    "\n",
    "\n",
    "#### Step 1 - creating the map dataset and the centre point\n",
    "\n",
    "All the data that Pydeck needs is in a pandas Dataframe.  Any Snowpark Dataframe can be converted to Pandas with the **to_pandas()** function. You will see that the dataframe contains a filter and this filter is determined by a Streamlit select-box.\n",
    "\n",
    "\n",
    "\n",
    "You also need to tell the map where the focal point is.  This is normally the **centre** of all the locations.  There are many techniques to work out the centre - for points, a nice simple way is by finding the average latitude and average longitude for all the points.  For polygons you can use **ST_CENTROID** to work out the centre of the polygon.  You could also use **ST_ENVELOPE** to create a bounding box - then work out the centre of  that bounding box.  This is useful if you have a variety of geographic shapes and want to work out the overall centre.  Solving this will make your map dynamic as you filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0e36c5-108a-431b-846b-849975f7bdbc",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "step_1"
   },
   "outputs": [],
   "source": [
    "types = names.select('TYPE').distinct()\n",
    "selectedtypes = st.selectbox('Select Type',types,1)\n",
    "snamesf = snames.filter(col('TYPE')==selectedtypes)\n",
    "center = snames.agg(avg('LAT'),avg('LON'))\n",
    "LAT = center.collect()[0][0]\n",
    "LON = center.collect()[0][1]\n",
    "st.write(center)\n",
    "placespd = snamesf.sample(0.5).limit(15000).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24543d1-b9a9-4e25-aad1-33a7247e8b4f",
   "metadata": {
    "collapsed": false,
    "name": "h_create_layer"
   },
   "source": [
    "#### Step 2 - Create a Layer\n",
    "\n",
    "The layer properties determine how to treat the layer.  It may be a polygon, point,path or H3 (there are also other options).  Each layer type will expect properties.  the properties can either be 'hard coded' or generated from the dataset.  In this case, LON and LAT is in the dataset so Pydeck will replace the word LON and LAT with the actual values from the dataframe.  the radius however is hardcoded (but it doesn't have to be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84f68f4-eb72-4916-8b9a-4c49a1ecb405",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "single_scatter_layer"
   },
   "outputs": [],
   "source": [
    "landcover_l = pdk.Layer(\n",
    "            'ScatterplotLayer',\n",
    "            data=placespd,\n",
    "            get_position='[LON, LAT]',\n",
    "            get_color='[41,181,232]',\n",
    "            get_radius=600,\n",
    "            pickable=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355dc07c-5e50-4d78-b344-0705253f77e0",
   "metadata": {
    "collapsed": false,
    "name": "H_STEP_3"
   },
   "source": [
    "### Step 3 - Render the map.\n",
    "\n",
    "\n",
    "Here, you will create a Pydeck visualisation, which is wrapped around a **Streamlit Pydeck** plugin object.  The Pydeck map in essence contains the following objects:\n",
    "\n",
    "- One or more layers.  The first layer we will work with is a scatterplot layer.  This will render points from Latitude and Longitude coordinates.\n",
    "\n",
    "- An Initial View State - This will include the centre point used to focus the the map on.  This will worked out dynamically from the data.  It will also contain an initial zoom level. \n",
    "\n",
    "- A tooltip - The tool tip is optional but highly recommended in order to disover insights about each datapoint visualised on the map. The tooltip will only display if **pickable** in the layer is set to **True**. Tooltips are parameterisd byusing curly brackets such as {YOUR_FIELD}. Wherever Pydeck sees a matching field in the dataset, it will replace the parameter with the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f150061-e1ec-4f8e-84cd-5415ca8bc51a",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "step_3_render_map"
   },
   "outputs": [],
   "source": [
    "st.pydeck_chart(pdk.Deck(\n",
    "    map_style=None,\n",
    "    initial_view_state=pdk.ViewState(\n",
    "        latitude=LAT,\n",
    "        longitude=LON,\n",
    "        zoom=5,\n",
    "        height=400\n",
    "        ),\n",
    "    \n",
    "layers= [landcover_l], tooltip = {'text':\"Place Name: {NAME1}, Type: {TYPE}\"}\n",
    "\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05d6c3c-b412-4733-9b8f-2e859642e223",
   "metadata": {
    "collapsed": false,
    "name": "heat_map"
   },
   "source": [
    "Simply switching the scatter-plot layer type to a heat-map layer type will give an alternative effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d7cfbe-1469-4a0e-b36d-56a751c047cb",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "heatmap"
   },
   "outputs": [],
   "source": [
    "### dropdown list creation\n",
    "types = names.select('TYPE').distinct()\n",
    "selectedtypes = st.selectbox('Select Type',types,2)\n",
    "\n",
    "## dataframe selection\n",
    "snamesf = snames.filter(col('TYPE')==selectedtypes)\n",
    "\n",
    "## center point generation\n",
    "center = snames.agg(avg('LAT'),avg('LON'))\n",
    "LAT = center.collect()[0][0]\n",
    "LON = center.collect()[0][1]\n",
    "st.write(center)\n",
    "\n",
    "## convert dataframe to pandas dataframe\n",
    "placespd = snamesf.sample(0.5).limit(15000).to_pandas()\n",
    "\n",
    "\n",
    "## create a heatmap layer\n",
    "landcover_l = pdk.Layer(\n",
    "            'HeatmapLayer',\n",
    "            data=placespd,\n",
    "            get_position='[LON, LAT]',\n",
    "            get_color='[41,181,232]',\n",
    "            get_radius=600,\n",
    "            pickable=True)\n",
    "\n",
    "#### render the map to include the layer\n",
    "    \n",
    "st.pydeck_chart(pdk.Deck(\n",
    "    map_style=None,\n",
    "    initial_view_state=pdk.ViewState(\n",
    "        latitude=LAT,\n",
    "        longitude=LON,\n",
    "        zoom=4,\n",
    "        height=400\n",
    "        ),\n",
    "    \n",
    "layers= [landcover_l], tooltip = {'text':\"Place Name: {NAME1}, Type: {TYPE}\"}\n",
    "\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f05da8-cd62-4605-a5ab-c07927a12604",
   "metadata": {
    "collapsed": false,
    "name": "points_mulit_map"
   },
   "source": [
    "#### Points on a Multi-layer Map\n",
    "Here, the data is split into multiple layers.  As each layer all consist of points, a simple function in order to reuse the same Layer properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149e8c3f-f959-4fd1-a3e5-a5a3ad934102",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "scatter_layer"
   },
   "outputs": [],
   "source": [
    "def layer(df,color):\n",
    "    \n",
    "    dfpd = df.sample(0.5).limit(1000).to_pandas()\n",
    "    return pdk.Layer(\n",
    "            'ScatterplotLayer',\n",
    "            data=dfpd,\n",
    "            get_position='[LON, LAT]',\n",
    "            get_color=color,\n",
    "            get_radius=10,\n",
    "            radiusScale=100,\n",
    "            pickable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e069a9a-df1c-41a1-b645-91a1bea9ee86",
   "metadata": {
    "collapsed": false,
    "name": "h_region_filter"
   },
   "source": [
    "You will generate a list of regions which will be used to create a new filter.  the previous **TYPE** filter will not be used, as we will overlay each type as a different layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6ad19d-c2e1-4853-9b78-ad3db7143182",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "distinct_regions"
   },
   "outputs": [],
   "source": [
    "reg = snames.select('REGION').distinct()\n",
    "reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada56438-624d-4c6b-b6c0-63f58e8a1d57",
   "metadata": {
    "collapsed": false,
    "name": "h_multi_layer_intro"
   },
   "source": [
    "Below is the Streamlit code for the new mullt-layered Pydeck point map.  Please note that there is one tool-tip which works for **ALL LAYERS**.  In terms of best practices, keep each layer consistant in terms of naming conventions especially if you want them to be pickable for tool tip purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d7c170-19a5-452f-9709-a31b715f228a",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "viewing_multiple_layers"
   },
   "outputs": [],
   "source": [
    "import pydeck as pdk\n",
    "\n",
    "## create a select box for each distinct region\n",
    "reg = snames.select('REGION').distinct()\n",
    "selected_region = st.selectbox('Select Regions',reg)\n",
    "\n",
    "## filter the dataframe by region\n",
    "snamesf = snames.filter(col('REGION')==selected_region)\n",
    "\n",
    "### use filtered dataframe to create 6 datafreames - each filtered to a different type\n",
    "landform = snamesf.filter(col('TYPE')=='landform')\n",
    "transportNetwork = snamesf.filter(col('TYPE')=='transportNetwork')\n",
    "landcover = snamesf.filter(col('TYPE')=='landcover')\n",
    "hydrography = snamesf.filter(col('TYPE')=='hydrography')\n",
    "other = snamesf.filter(col('TYPE')=='other')\n",
    "populatedPlace = snamesf.filter(col('TYPE')=='populatedPlace')\n",
    "\n",
    "### create the center point\n",
    "center = snamesf.agg(avg('LAT'),avg('LON'))\n",
    "LAT = center.collect()[0][0]\n",
    "LON = center.collect()[0][1]\n",
    "st.write(center)\n",
    "\n",
    "\n",
    "#### render the map for each layer by calling the layer function that was previously created\n",
    "landcover_l = layer(landcover,'[41,181,232]')\n",
    "transport_l = layer(transportNetwork,'[17,86,127]')\n",
    "landform_l = layer(landform,'[0,0,0]')\n",
    "other_l = layer(other,'[138,153,158]')\n",
    "hydrography_l = layer(hydrography,'[113,221,220]')\n",
    "\n",
    "#### visualise the  results in pydeck.\n",
    "st.pydeck_chart(pdk.Deck(\n",
    "    map_style=None,\n",
    "    initial_view_state=pdk.ViewState(\n",
    "        latitude=LAT,\n",
    "        longitude=LON,\n",
    "        zoom=7,\n",
    "        height=400\n",
    "        ),\n",
    "    \n",
    "layers= [landcover_l,transport_l,landform_l,other_l,hydrography_l], tooltip = {'text':\"Place Name: {NAME1}, Type: {TYPE}\"}\n",
    "\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481cee57-c8fb-442c-913b-2db4deea37c0",
   "metadata": {
    "collapsed": false,
    "name": "_2b_polygons"
   },
   "source": [
    "## 2b. Handling Polygons\n",
    "Let's now utilise polygons.  Polygons consist of multiple points.  For a polygon to be valid, the last point is always the same as the first point.  We will use polygons to filter another dataset which is the urban extents dataset.  This dataset has 2 location fields - \n",
    "\n",
    "- **GEOMETRY**.  This column can be aligned to any grid reference system - in this case, its aligned to the British National Reference system.  You will also note that the data is stored in 'WKT'(Well Known Text) Format.  \n",
    "\n",
    "- **GEOGRAPHY** - Same as before, The Geography column models the earth as though it were a perfect sphere and follows the WGS 84 standard.  The data is stored as Geojson format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1aef62-a375-4c16-a068-c27b128ff4a7",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "heading_extents"
   },
   "outputs": [],
   "source": [
    "urban_extents = session.table('URBAN_EXTENTS_FOR_CITIES_TOWNS_AND_VILLAGES__GREAT_BRITAIN_OPEN_BUILT_UP_AREAS.PRS_OPEN_BUILT_UP_AREAS_SCH.PRS_OPEN_BUILT_UP_AREAS_TBL')\n",
    "urban_extents.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d9a8f-5edc-49b6-80d4-400a61c1a295",
   "metadata": {
    "collapsed": false,
    "name": "heading_multi_polygons"
   },
   "source": [
    "ou will note that the geography datatype consists of polygons containing both **multi-polygons** and **polygons**.  Multi-Polygons nest several polygons as one object.   the Pydeck Library can only visualise polygons which are not nested as Multi-polygons.  To resolve this,  a simple function is created to transform all multi-polygons to polygons so it's easier for **Pydeck** to handle.  This involves **flattening** the multi-polygons into multiple rows.  Snowflake's semi-structured support allows this to happen natively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb39287-7d66-4cfa-9a97-775788fde17e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "convert_to_polygons"
   },
   "outputs": [],
   "source": [
    "def polygon(data):\n",
    "    # create a new data frame filter the dataframe where the type in each geography field contains the word 'Polygon'\n",
    "    dataP = data.filter(call_function('ST_ASGEOJSON',col('GEOGRAPHY'))['type'].astype(StringType())=='Polygon')\n",
    "    # create a new dataframe and Filter the dataframe where the type in each geography field contains the word 'Multi Polygon'\n",
    "    dataM = data.filter(call_function('ST_ASGEOJSON',col('GEOGRAPHY'))['type'].astype(StringType())=='MultiPolygon')\n",
    "\n",
    "    ## use the join table function to flatten the multi polygon into one row per polygon\n",
    "    dataM = dataM.join_table_function('flatten',\n",
    "                                        call_function('ST_ASGEOJSON',\n",
    "                                        col('GEOGRAPHY'))['coordinates']).drop('SEQ',\n",
    "                                                                               'KEY',\n",
    "                                                                               'PATH',\n",
    "                                                                               'INDEX',\n",
    "                                                                               'THIS')                                                                                                        \n",
    "    \n",
    "    ## With the flattend results, create a new valid geography object with the type 'Polygon'\n",
    "    dataM = dataM.with_column('GEOGRAPHY',\n",
    "                                to_geography(object_construct(lit('coordinates'),\n",
    "                                                        to_array('VALUE'),\n",
    "                                                        lit('type'),\n",
    "                                                        lit('Polygon')))).drop('VALUE')\n",
    "\n",
    "    ### return both the converted polygons (dataM) as well as the already single polygons (dataP) into one dataframe\n",
    "\n",
    "    return dataM.union(dataP).with_column_renamed('GEOGRAPHY','POLYGON')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d069592-b5f5-43cd-9b22-cb61259407af",
   "metadata": {
    "collapsed": false,
    "name": "view_polygons"
   },
   "source": [
    "Now we have our new function to convert the polygons, we can render them easily in pydeck.\n",
    "\n",
    "- Run the cell below which uses the new function. \n",
    "- Double click in the geography column to see the result.  \n",
    "\n",
    "As we have one polygon per row, we might want to consider the handling of the metrics.  Below, we have added an **AREA_KM** column which will return area per polygon rather than the Area_hectares which returned the sum of all polygons inside the multi polygon.\n",
    "\n",
    "Finally we will write a **new table** using the **write** command and will call it **Urban Extents**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554fd6d9-2e18-45f3-a9aa-587a434e36cc",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "calling_function"
   },
   "outputs": [],
   "source": [
    "raw_data = session.table('URBAN_EXTENTS_FOR_CITIES_TOWNS_AND_VILLAGES__GREAT_BRITAIN_OPEN_BUILT_UP_AREAS.PRS_OPEN_BUILT_UP_AREAS_SCH.PRS_OPEN_BUILT_UP_AREAS_TBL')\n",
    "dataset = polygon(raw_data.drop('GEOMETRY'))\n",
    "dataset = dataset.with_column('AREA_KM',div0(call_function('ST_AREA',col('POLYGON')),1000).astype(DecimalType(8,2)))\n",
    "dataset = dataset.with_column('AREA_HECTARES',div0(call_function('ST_AREA',col('POLYGON')),10000).astype(DecimalType(8,2)))\n",
    "dataset.write.mode('overwrite').save_as_table(\"DEFAULT_SCHEMA.URBAN_EXTENTS\")\n",
    "dataset = session.table('DEFAULT_SCHEMA.URBAN_EXTENTS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c64036-18a3-4fae-a81e-a8964663bcaf",
   "metadata": {
    "collapsed": false,
    "name": "tooltip_h"
   },
   "source": [
    "Before we see the results, run the code below to create a new tool-tip which has HTML styling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a610bb6-2ebf-41a1-85b0-1e1d7a8bdffc",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "better_tooltip"
   },
   "outputs": [],
   "source": [
    "tooltip = {\n",
    "   \"html\": \"\"\"<b>Name:</b> {NAME1_TEXT} <br> <b>Area KM:</b> {AREA_KM} <br> <b>Area Hectares:</b> {AREA_HECTARES}\"\"\",\n",
    "   \"style\": {\n",
    "       \"width\":\"50%\",\n",
    "        \"backgroundColor\": \"steelblue\",\n",
    "        \"color\": \"white\",\n",
    "       \"text-wrap\": \"balance\"\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e2436-e005-4732-94a4-545d9f93494c",
   "metadata": {
    "collapsed": false,
    "name": "results"
   },
   "source": [
    "Below are the results of the polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c74aec-866f-4e66-af18-266a802dea78",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "visualise_extents"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pydeck as pdk\n",
    "import json\n",
    "session = get_active_session()\n",
    "from snowflake.snowpark.functions import *\n",
    "st.subheader('OS Urban Extents - Built up Extents for cities, towns and villages')\n",
    "### create a filter dropdown using distinct urban extent values\n",
    "\n",
    "filter = dataset.select('NAME1_TEXT').distinct()\n",
    "filter = st.selectbox('Choose Town:',filter)\n",
    "data = dataset.filter(col('NAME1_TEXT')==filter)\n",
    "\n",
    "### create a center point - this time using the centroid method as we are visualising one polygon at a time\n",
    "centre = data.with_column('CENTROID',call_function('ST_CENTROID',col('POLYGON')))\n",
    "centre = centre.with_column('LON',call_function('ST_X',col('CENTROID')))\n",
    "centre = centre.with_column('LAT',call_function('ST_Y',col('CENTROID')))\n",
    "\n",
    "centrepd = centre.select('LON','LAT').to_pandas()\n",
    "LON = centrepd.LON.iloc[0]\n",
    "LAT = centrepd.LAT.iloc[0]\n",
    "\n",
    "\n",
    "# convert the dataframe to pandas and use a pandas lamda function to extract the coordinates out of each polygon.  \n",
    "##pydeck only requires sets of coordinates in arrays, not the polygon itself\n",
    "\n",
    "datapd = data.to_pandas()\n",
    "\n",
    "datapd[\"coordinates\"] = datapd[\"POLYGON\"].apply(lambda row: json.loads(row)[\"coordinates\"])\n",
    "\n",
    "\n",
    "\n",
    "# Create data layer for each polygon\n",
    "data_layer = pdk.Layer(\n",
    "    \"PolygonLayer\",\n",
    "    datapd,\n",
    "    opacity=0.3,\n",
    "    get_polygon=\"coordinates\", \n",
    "    filled=True,\n",
    "    get_fill_color=[255, 0, 127],\n",
    "    get_line_color=[0, 0, 0],\n",
    "    auto_highlight=True,\n",
    "    pickable=True,\n",
    ")\n",
    "\n",
    "# Set the view on the map\n",
    "view_state = pdk.ViewState(\n",
    "    longitude=LON,\n",
    "    latitude=LAT,\n",
    "    zoom=13,  # Adjust zoom if needed\n",
    "    pitch=0,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Render the map with layer and tooltip\n",
    "r = pdk.Deck(\n",
    "    layers=[data_layer],\n",
    "    initial_view_state=view_state,\n",
    "    map_style=None,\n",
    "    tooltip=tooltip)\n",
    "    \n",
    "st.pydeck_chart(r, use_container_width=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebf2598-3938-46a4-8f95-7e66a7da63ab",
   "metadata": {
    "collapsed": false,
    "name": "linestrings"
   },
   "source": [
    "## 2c. Handling Linestrings\n",
    "\n",
    "Line strings consist of multiple points to form a line. Similar to polygons, you can also have both multi line strings and line strings.\n",
    "\n",
    "line-string handling is of similar nature to polygons.  Pydeck does not supported 'nested' line string - each line needs to be rendered in a separate row.  Therefore we will create another function - similar as before to convert multi-linestrings to linestrings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0fccc0-d02e-4c09-a020-e1a1f3df5a9a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "linestring_function"
   },
   "outputs": [],
   "source": [
    "def linestring(data):\n",
    "    # create a new data frame filter the dataframe where the type in each geography field contains the word 'Line String'\n",
    "    dataP = data.filter(call_function('ST_ASGEOJSON',col('GEOGRAPHY'))['type'].astype(StringType())=='LineString')\n",
    "    # create a new dataframe and Filter the dataframe where the type in each geography field contains the word 'Multi Line String'\n",
    "    dataM = data.filter(call_function('ST_ASGEOJSON',col('GEOGRAPHY'))['type'].astype(StringType())=='MultiLinesting')\n",
    "    ## use the join table function to flatten the multi Line String into one row per Line String\n",
    "    dataM = dataM.join_table_function('flatten',\n",
    "                                        call_function('ST_ASGEOJSON',\n",
    "                                        col('GEOGRAPHY'))['coordinates']).drop('SEQ',\n",
    "                                                                               'KEY',\n",
    "                                                                               'PATH',\n",
    "                                                                               'INDEX',\n",
    "                                                                               'THIS')\n",
    "    \n",
    "    ## With the flattend results, create a new valid geography object with the type 'Line String'.                                                                                                        \n",
    "    dataM = dataM.with_column('GEOGRAPHY',\n",
    "                                to_geography(object_construct(lit('coordinates'),\n",
    "                                                        to_array('VALUE'),\n",
    "                                                        lit('type'),\n",
    "                                                        lit('LineString')))).drop('VALUE')\n",
    "    ### return both the converted linestrings (dataM) as well as the already single linestrings (dataP) into one dataframe\n",
    "    return dataM.union(dataP).with_column_renamed('GEOGRAPHY','LINESTRING')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8010c620-af09-4e96-98a6-322322c66199",
   "metadata": {
    "collapsed": false,
    "name": "heading_vehicle_network"
   },
   "source": [
    "A perfect dataset to visualise linestrings is the vehicle network.  Below we will put the multi-linestrings through the line string function and then persist the results into a new table called **ROAD_LINKS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e8d8e-cca6-4291-aedc-6af3b464817b",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "heading_network"
   },
   "outputs": [],
   "source": [
    "road_link = session.table('ROAD_NETWORK__GREAT_BRITAIN_OPEN_ROADS.PRS_OPENROADS_SCH.PRS_ROAD_LINK_TBL')\n",
    "road_link.limit(5)\n",
    "\n",
    "dataset2 = linestring(road_link)\n",
    "dataset2.write.mode('overwrite').save_as_table(\"DEFAULT_SCHEMA.ROAD_LINKS\")\n",
    "dataset2 = session.table('DEFAULT_SCHEMA.ROAD_LINKS')\n",
    "dataset2.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb3ad05-fae8-491c-ab27-5da48f272903",
   "metadata": {
    "collapsed": false,
    "name": "view_road"
   },
   "source": [
    "From a **Pydeck** prospective, to visualise line strings, you will use the **PathLayer**.  Remember this time we are visualising lines, so the line width may more significant here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc6048-aef2-43a6-84ee-6e60c89e3312",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "path_layer"
   },
   "outputs": [],
   "source": [
    "#Path layer for road network\n",
    "network_layer  = pdk.Layer(\n",
    "        type=\"PathLayer\",\n",
    "        data=datapd,\n",
    "        pickable=True,\n",
    "        get_color=[170, 74, 68],\n",
    "        width_scale=5,\n",
    "        opacity = 1,\n",
    "        width_min_pixels=2,\n",
    "        get_path=\"coordinates\",\n",
    "        get_width=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a5de95-03f5-4480-9a9b-d428d36a0019",
   "metadata": {
    "collapsed": false,
    "name": "heading_road_network"
   },
   "source": [
    "The filter used for this data frame is based on road classifaction number and road type.  You will be able to select both of these and it will draw the road.  This illustration will only draw one row at a time.  The filtering works the same way as before.\n",
    "\n",
    "For the center point, **ST_ENVELOPE** is used to effectively draw a square around the line. **ST_CENTROID** is then used to find the centre of the square.\n",
    "\n",
    "You will also note that **ST_AREA** is used to calculate the area in square metres. This is then used as a condition for the zoom level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297978fb-39f0-4c97-b690-5262e1ad5704",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "road_network_map"
   },
   "outputs": [],
   "source": [
    "tooltip = {\n",
    "   \"html\": \"\"\"<b>Name:</b> {NAME_1} <br> <b>Form of Way:</b> {FORM_OF_WAY} <br> <b>Length:</b> {LENGTH}\"\"\",\n",
    "   \"style\": {\n",
    "       \"width\":\"50%\",\n",
    "        \"backgroundColor\": \"steelblue\",\n",
    "        \"color\": \"white\",\n",
    "       \"text-wrap\": \"balance\"\n",
    "   }\n",
    "}\n",
    "\n",
    "\n",
    "import json\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pydeck as pdk\n",
    "import json\n",
    "session = get_active_session()\n",
    "from snowflake.snowpark.functions import *\n",
    "\n",
    "dataset2 = session.table('DEFAULT_SCHEMA.ROAD_LINKS')\n",
    "dataset2 = dataset2.filter(col('ROAD_CLASSIFICATION_NUMBER')!='None')\n",
    "\n",
    "filter = dataset2.select('ROAD_CLASSIFICATION').distinct()\n",
    "\n",
    "\n",
    "filter = st.selectbox('Choose Road Type:',filter)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = dataset2.filter(col('ROAD_CLASSIFICATION')==filter)\n",
    "filter2 = data.select('ROAD_CLASSIFICATION_NUMBER').distinct()\n",
    "filter2 = st.selectbox('Choose Classification Number:',filter2)\n",
    "data = data.filter(col('ROAD_CLASSIFICATION_NUMBER')==filter2)\n",
    "button = st.button('Submit Options')\n",
    "\n",
    "if button:\n",
    "\n",
    "    centre = data.select(call_function('ST_COLLECT',col('LINESTRING')).alias('CENTROID'))\n",
    "    centre = centre.with_column('CENTROID',call_function('ST_ENVELOPE',col('CENTROID')))\n",
    "    centre = centre.with_column('AREA',call_function('ST_AREA',col('CENTROID')))\n",
    "    centre = centre.with_column('CENTROID',call_function('ST_CENTROID',col('CENTROID')))\n",
    "    centre = centre.with_column('LON',call_function('ST_X',col('CENTROID')))\n",
    "    centre = centre.with_column('LAT',call_function('ST_Y',col('CENTROID')))\n",
    "\n",
    "    centrepd = centre.select('LON','LAT','AREA').to_pandas()\n",
    "    LON = centrepd.LON.iloc[0]\n",
    "    LAT = centrepd.LAT.iloc[0]\n",
    "    AREA = centrepd.AREA.iloc[0]\n",
    "\n",
    "    zoom = 10\n",
    "\n",
    "    if AREA < 100:\n",
    "        zoom=24\n",
    "    elif AREA < 10000:\n",
    "        zoom=20\n",
    "    elif AREA < 100000:\n",
    "        zoom=15\n",
    "    elif AREA < 1000000:\n",
    "        zoom=12\n",
    "    elif AREA < 10000000:\n",
    "        zoom=10\n",
    "    elif AREA < 100000000:\n",
    "        zoom=9\n",
    "    elif AREA < 1000000000:\n",
    "        zoom=8\n",
    "    elif AREA < 10000000000:\n",
    "        zoom=5\n",
    "    elif AREA < 100000000000:\n",
    "        zoom=3\n",
    "\n",
    "    else: \n",
    "        zoom=1\n",
    "    \n",
    "\n",
    "    st.write(AREA)\n",
    "# Populate dataframe from query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd90c10-7e2a-458a-a9e3-92a8d5f79d5f",
   "metadata": {
    "collapsed": false,
    "name": "map_render"
   },
   "source": [
    "Render the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d7c28-bbf8-4bee-8a12-3945bdac8ef2",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "render_map"
   },
   "outputs": [],
   "source": [
    "datapd = data.to_pandas()\n",
    "\n",
    "datapd[\"coordinates\"] = datapd[\"LINESTRING\"].apply(lambda row: json.loads(row)[\"coordinates\"])\n",
    "\n",
    "st.write('OS Open Roads')\n",
    "st.write(datapd)\n",
    "\n",
    "#Path layer for road network\n",
    "network_layer  = pdk.Layer(\n",
    "        type=\"PathLayer\",\n",
    "        data=datapd,\n",
    "        pickable=True,\n",
    "        get_color=[170, 74, 68],\n",
    "        width_scale=5,\n",
    "        opacity = 1,\n",
    "        width_min_pixels=2,\n",
    "        get_path=\"coordinates\",\n",
    "        get_width=2,\n",
    ")\n",
    "\n",
    "# Set the view on the map\n",
    "view_state = pdk.ViewState(\n",
    "        longitude=LON,\n",
    "        latitude=LAT,\n",
    "        zoom=zoom,  # Adjust zoom if needed\n",
    "        pitch=0,\n",
    "    )\n",
    "\n",
    "# Render the map with layer and tooltip\n",
    "r = pdk.Deck(\n",
    "    layers=[network_layer],\n",
    "    initial_view_state=view_state,\n",
    "    map_style=None,\n",
    "    tooltip=tooltip)\n",
    "    \n",
    "\n",
    "st.pydeck_chart(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4e4bad-018a-4f23-ae71-2a275eb81692",
   "metadata": {
    "collapsed": false,
    "name": "create_spatial_filter"
   },
   "source": [
    "# 3. Create a Spatial Filter\n",
    "Previously, we leveraged the urban extents visualise polygons.  This time, we will use the same polygons to filter line strings.  This is performed by using a spatial filter.  We will also  view multiple layers again - this time however, containing points and lines.  The points represent the road nodes and the lines represent the road links.\n",
    "\n",
    "Filtering is performed by creating an inner join between the towns and the roads.  **ST_INTERSECTS** joins only when a road crosses a town.  The filter this time are the towns.  Run the code below to view only road links that cross over the town"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb5d48c-f92f-4d90-8913-be5ff8c8d587",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "road_links_in_town"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pydeck as pdk\n",
    "import json\n",
    "session = get_active_session()\n",
    "from snowflake.snowpark.functions import *\n",
    "\n",
    "filter = dataset.select('NAME1_TEXT').distinct()\n",
    "filter = st.selectbox('Choose Town:',filter,4)\n",
    "data = dataset.filter(col('NAME1_TEXT')==filter)\n",
    "dataset3 = session.table('DEFAULT_SCHEMA.ROAD_LINKS')\n",
    "\n",
    "#### the join to only view results if the road crosses over the town\n",
    "\n",
    "datajoined = data.join(dataset3,call_function('ST_INTERSECTS',data['POLYGON'],dataset3['LINESTRING']))\n",
    "\n",
    "\n",
    "centre = datajoined.with_column('CENTROID',call_function('ST_CENTROID',col('POLYGON')))\n",
    "centre = centre.with_column('LON',call_function('ST_X',col('CENTROID')))\n",
    "centre = centre.with_column('LAT',call_function('ST_Y',col('CENTROID')))\n",
    "\n",
    "datajoined = datajoined.drop('POLYGON')\n",
    "\n",
    "centrepd = centre.select('LON','LAT').to_pandas()\n",
    "LON = centrepd.LON.iloc[0]\n",
    "LAT = centrepd.LAT.iloc[0]\n",
    "# Populate dataframe from query\n",
    "\n",
    "datapd = datajoined.to_pandas()\n",
    "\n",
    "datapd[\"coordinates\"] = datapd[\"LINESTRING\"].apply(lambda row: json.loads(row)[\"coordinates\"])\n",
    "\n",
    "\n",
    "\n",
    "# Create data layer - this where the geometry is likely failing - column is now called geometry to match geopandas default\n",
    "network_layer  = pdk.Layer(\n",
    "        type=\"PathLayer\",\n",
    "        data=datapd,\n",
    "        pickable=True,\n",
    "        get_color=[170, 74, 68],\n",
    "        width_scale=5,\n",
    "        opacity = 1,\n",
    "        width_min_pixels=2,\n",
    "        get_path=\"coordinates\",\n",
    "        get_width=2,\n",
    ")\n",
    "\n",
    "# Set the view on the map\n",
    "view_state = pdk.ViewState(\n",
    "    longitude=LON,\n",
    "    latitude=LAT,\n",
    "    zoom=13,  # Adjust zoom if needed\n",
    "    pitch=0,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Render the map with layer and tooltip\n",
    "r = pdk.Deck(\n",
    "    layers=[network_layer],\n",
    "    initial_view_state=view_state,\n",
    "    map_style=None,\n",
    "    tooltip=tooltip)\n",
    "    \n",
    "st.pydeck_chart(r, use_container_width=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30911b16-33a9-491d-995c-4c389308d1b0",
   "metadata": {
    "collapsed": false,
    "name": "road_nodes_h"
   },
   "source": [
    "Let's now combine with the Road Nodes - these are points.  We can use the same intersect join to map our nodes with the road details.  The dataframe has been modified slightly so it is consistant with the previous dataframe.  Tooltips for multi-layers require the same naming parameters, so padding out additional columns with 'N/A' is helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf20bc5-3722-4960-864a-2aef61212a99",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "filter_road_nodes"
   },
   "outputs": [],
   "source": [
    "road_nodes = session.table('ROAD_NETWORK__GREAT_BRITAIN_OPEN_ROADS.PRS_OPENROADS_SCH.PRS_ROAD_NODE_TBL')\n",
    "road_nodes = road_nodes.withColumnRenamed('FORM_OF_ROAD_NODE','FORM_OF_WAY')\n",
    "road_nodes = road_nodes.withColumn('NAME_1',lit('N/A'))\n",
    "road_nodes = road_nodes.withColumn('LENGTH',lit('N/A'))\n",
    "road_nodes.with_column_renamed('GEOGRAPHY','POINT').write.mode('overwrite').save_as_table(\"DEFAULT_SCHEMA.ROAD_NODES\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fd8fd0-b4fc-4998-aca6-31d48264ef54",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "filter_nodes"
   },
   "outputs": [],
   "source": [
    "road_nodes = session.table('DEFAULT_SCHEMA.road_nodes')\n",
    "nodes_filtered = road_nodes.join(datajoined.select('LINESTRING'),call_function('ST_INTERSECTS',\n",
    "                                         datajoined['LINESTRING'],road_nodes['POINT'])).drop('LINESTRING')\n",
    "\n",
    "\n",
    "st.write(nodes_filtered.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e627d9f9-524d-4b53-a836-741cb8d4bbb4",
   "metadata": {
    "collapsed": false,
    "name": "heading_road_network_multi_layer"
   },
   "source": [
    "Below you should now see a multi-layer map consisting of the road nodes as well as the road segments themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498fbdb0-aaf5-43be-b90a-e90287a06e44",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "nodes_with_junctions"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pydeck as pdk\n",
    "import json\n",
    "from snowflake.snowpark.types import *\n",
    "from snowflake.snowpark.functions import *\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "\n",
    "\n",
    "tooltip = {\n",
    "   \"html\": \"\"\"<b>Name:</b> {NAME_1} <br> <b>Form of Way:</b> {FORM_OF_WAY} <br> <b>Length:</b> {LENGTH}\"\"\",\n",
    "   \"style\": {\n",
    "       \"width\":\"50%\",\n",
    "        \"backgroundColor\": \"steelblue\",\n",
    "        \"color\": \"white\",\n",
    "       \"text-wrap\": \"balance\"\n",
    "   }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "road_links = session.table('DEFAULT_SCHEMA.ROAD_LINKS')\n",
    "urban_extents = session.table('DEFAULT_SCHEMA.URBAN_EXTENTS')\n",
    "road_nodes = session.table('DEFAULT_SCHEMA.ROAD_NODES')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filter = urban_extents.select('NAME1_TEXT').distinct()\n",
    "filter = st.selectbox('Choose Town:',filter,7)\n",
    "data = urban_extents.filter(col('NAME1_TEXT')==filter)\n",
    "\n",
    "\n",
    "datajoined = data.join(road_links,call_function('ST_INTERSECTS',data['POLYGON'],road_links['LINESTRING']))\n",
    "\n",
    "\n",
    "\n",
    "nodes_filtered = road_nodes.join(datajoined.select('LINESTRING'),call_function('ST_INTERSECTS',\n",
    "                                         datajoined['LINESTRING'],road_nodes['POINT'])).drop('LINESTRING')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "centre = datajoined.with_column('CENTROID',call_function('ST_CENTROID',col('POLYGON')))\n",
    "centre = centre.with_column('LON',call_function('ST_X',col('CENTROID')))\n",
    "centre = centre.with_column('LAT',call_function('ST_Y',col('CENTROID')))\n",
    "\n",
    "datajoined = datajoined.drop('POLYGON')\n",
    "\n",
    "centrepd = centre.select('LON','LAT').to_pandas()\n",
    "LON = centrepd.LON.iloc[0]\n",
    "LAT = centrepd.LAT.iloc[0]\n",
    "# Populate dataframe from query\n",
    "\n",
    "datapd = datajoined.to_pandas()\n",
    "\n",
    "datapd[\"coordinates\"] = datapd[\"LINESTRING\"].apply(lambda row: json.loads(row)[\"coordinates\"])\n",
    "\n",
    "\n",
    "\n",
    "# Create data layer - this where the geometry is likely failing - column is now called geometry to match geopandas default\n",
    "network_layer  = pdk.Layer(\n",
    "        type=\"PathLayer\",\n",
    "        data=datapd,\n",
    "        pickable=True,\n",
    "        get_color=[170, 74, 68],\n",
    "        width_scale=5,\n",
    "        opacity = 1,\n",
    "        width_min_pixels=2,\n",
    "        get_path=\"coordinates\",\n",
    "        get_width=2,\n",
    ")\n",
    "\n",
    "datajoined = datajoined.drop('POLYGON')\n",
    "\n",
    "nodes_filtered_2 = nodes_filtered.with_column('LAT',call_function('ST_Y',col('POINT')))\n",
    "nodes_filtered_2 = nodes_filtered_2.with_column('LON',call_function('ST_X',col('POINT')))\n",
    "nodes_filtered_2 = nodes_filtered_2.drop('POINT')\n",
    "# Create data layer - this where the geometry is likely failing - column is now called geometry to match geopandas default\n",
    "nodes = pdk.Layer(\n",
    "            'ScatterplotLayer',\n",
    "            data=nodes_filtered_2.to_pandas(),\n",
    "            get_position='[LON, LAT]',\n",
    "            get_color='[41,181,232]',\n",
    "            get_radius=20,\n",
    "            pickable=True)\n",
    "\n",
    "# Set the view on the map\n",
    "view_state = pdk.ViewState(\n",
    "    longitude=LON,\n",
    "    latitude=LAT,\n",
    "    zoom=13,  # Adjust zoom if needed\n",
    "    pitch=0,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Render the map with layer and tooltip\n",
    "r = pdk.Deck(\n",
    "    layers=[network_layer,nodes],\n",
    "    initial_view_state=view_state,\n",
    "    map_style=None,\n",
    "    tooltip=tooltip)\n",
    "    \n",
    "st.pydeck_chart(r, use_container_width=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2054005c-bd75-41e3-8d15-8ff73a821c78",
   "metadata": {
    "collapsed": false,
    "name": "h_search_optimisation"
   },
   "source": [
    "To avoid re-applying the same linestring transformations let's persist this information.  We will then speed up the search capability of the table on the geography columns by applying **Search Optimisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bf2e11-7d9e-4825-8946-9d5c8a93fc97",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "search_optimisation"
   },
   "outputs": [],
   "source": [
    "ALTER TABLE DEFAULT_SCHEMA.ROAD_LINKS ADD SEARCH OPTIMIZATION ON GEO(LINESTRING);\n",
    "\n",
    "ALTER TABLE DEFAULT_SCHEMA.URBAN_EXTENTS ADD SEARCH OPTIMIZATION ON GEO(POLYGON);\n",
    "\n",
    "ALTER TABLE DEFAULT_SCHEMA.ROAD_NODES ADD SEARCH OPTIMIZATION ON GEO(POINT);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947ac625-ead4-4771-8731-9bac1f19e031",
   "metadata": {
    "collapsed": false,
    "name": "H3"
   },
   "source": [
    "# 4. H3\n",
    "Snowflake supports the popular H3 indexing system.  It is very easy to convert points to H3 as well as covering polygons.  The simple excercise we will cover today, is converting the points that we used in section 2 of the lab to H3.  We will use the function **H3_POINT_TO_CELL_STRING(point,resolution)**.  \n",
    "\n",
    "H3 allows for fast processing using multiple resolutions.  H3 works well using gradients.  To do this you might want to influence the RGB colour by creating a weighting between 0 and 255'.\n",
    "\n",
    "This time, SQL is used to convert the data to H3.  The results of this is then visualised in a Pydeck map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781f29f5-82a3-4e0c-b3aa-6a136784add4",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "h3_lev_5"
   },
   "outputs": [],
   "source": [
    "SELECT H3_POINT_TO_CELL_STRING(GEOGRAPHY,7) H3, TYPE, COUNT(*) COUNT,\n",
    "\n",
    "(COUNT - MIN(COUNT) OVER (PARTITION BY TYPE)) / \n",
    "    NULLIF(MAX(COUNT) OVER (PARTITION BY TYPE) - MIN(COUNT) OVER (PARTITION BY TYPE) , 0) RATIO,\n",
    "    RATIO * 41 AS R,\n",
    "    RATIO  * 181 AS G,\n",
    "    RATIO * 232 AS B\n",
    "\n",
    "\n",
    "\n",
    "FROM (\n",
    "select * from POSTCODES_PLACE_NAMES_AND_ROAD_NUMBERS__GREAT_BRITAIN_OPEN_NAMES.PRS_OPEN_NAMES_SCH.PRS_OPEN_NAMES_TBL) GROUP BY ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda28d39-ada9-4492-a91b-aeb0758046e8",
   "metadata": {
    "collapsed": false,
    "name": "hd_filter_type"
   },
   "source": [
    "Here is the new H3 layer which the H3 dataframe is assigned with.  Before assignment,  a **TYPE** filter is controlled by the user,which will be selected before the visualisation is rendered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab5859a-5cbe-47c6-954a-c08d6d913aef",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "h3_layer"
   },
   "outputs": [],
   "source": [
    "s_types = h3_lev_5.to_df().select('TYPE').distinct()\n",
    "\n",
    "filter_type = st.radio('Select Type: ', s_types)\n",
    "\n",
    "\n",
    "h3pd = h3_lev_5.to_df().filter(col('TYPE')==filter_type).to_pandas()\n",
    "h3 = pdk.Layer(\n",
    "        \"H3HexagonLayer\",\n",
    "        h3pd,\n",
    "        pickable=True,\n",
    "        stroked=True,\n",
    "        filled=True,\n",
    "        extruded=False,\n",
    "        get_hexagon=\"H3\",\n",
    "        get_fill_color=[\"R\",\"G\",\"B\"],\n",
    "        line_width_min_pixels=0,\n",
    "        opacity=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35ef837-5a45-4122-9f21-cd13b40ba777",
   "metadata": {
    "collapsed": false,
    "name": "rendered_h3"
   },
   "source": [
    "This is the rendered H3 output\n",
    "\n",
    "The higher the resolution, the smaller the hexagon.  The lower the resolution, the larger the hexagon.  Next you will learn about changing the resolution dynamically\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb09d1d4-253e-4cf3-85df-d872dd5cb97c",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "render_h3"
   },
   "outputs": [],
   "source": [
    "s_types = h3_lev_5.to_df().select('TYPE').distinct()\n",
    "\n",
    "filter_type = st.radio('Select Type: ', s_types,2)\n",
    "\n",
    "\n",
    "h3pd = h3_lev_5.to_df().filter(col('TYPE')==filter_type).to_pandas()\n",
    "h3 = pdk.Layer(\n",
    "        \"H3HexagonLayer\",\n",
    "        h3pd,\n",
    "        pickable=True,\n",
    "        stroked=True,\n",
    "        filled=True,\n",
    "        extruded=False,\n",
    "        get_hexagon=\"H3\",\n",
    "        get_fill_color=[\"R\",\"G\",\"B\"],\n",
    "        line_width_min_pixels=0,\n",
    "        opacity=0.4)\n",
    "\n",
    "tooltip = {\n",
    "   \"html\": \"\"\"<b>H3:</b> {H3} <br> <b>Count:</b> {COUNT}\"\"\",\n",
    "   \"style\": {\n",
    "       \"width\":\"50%\",\n",
    "        \"backgroundColor\": \"steelblue\",\n",
    "        \"color\": \"white\",\n",
    "       \"text-wrap\": \"balance\"\n",
    "   }\n",
    "}\n",
    "\n",
    "st.pydeck_chart(pdk.Deck(\n",
    "    map_style=None,\n",
    "    initial_view_state=pdk.ViewState(\n",
    "        latitude=LAT,\n",
    "        longitude=LON,\n",
    "        zoom=5,\n",
    "        height=600\n",
    "        ),\n",
    "    \n",
    "layers= [h3], tooltip = tooltip\n",
    "\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95477ea-805f-425f-af63-3deff225429d",
   "metadata": {
    "collapsed": false,
    "name": "hd_res_changes"
   },
   "source": [
    "### H3 Resolution changes\n",
    "\n",
    "It's possible to dynamically lower the resolution easily. Below an example of this using the function **H3_CELL_TO_PARENT_STRING**\n",
    "\n",
    "Remember, if the resolution is lowered, the data will need to be re-grouped.  Consideration is needed on how the measures are aggregated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6969dd-cce8-4e64-81da-10095debe5ea",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "h3_res_changes"
   },
   "outputs": [],
   "source": [
    "s_types = h3_lev_5.to_df().select('TYPE').distinct()\n",
    "\n",
    "filter_type2 = st.selectbox('Select Type: ', s_types)\n",
    "res = st.slider('Change Resolution:',1,7,7)\n",
    "\n",
    "h3 = h3_lev_5.to_df().with_column('H3',call_function('H3_CELL_TO_PARENT',col('H3'),res))\n",
    "\n",
    "h3pd = h3.filter(col('TYPE')==filter_type2).group_by('H3').agg(max('R').alias('R'),\n",
    "                                                          max('G').alias('G'),\n",
    "                                                          max('B').alias('B'),\n",
    "                                                          count('COUNT').alias('COUNT')).to_pandas()\n",
    "h3 = pdk.Layer(\n",
    "        \"H3HexagonLayer\",\n",
    "        h3pd,\n",
    "        pickable=True,\n",
    "        stroked=True,\n",
    "        filled=True,\n",
    "        extruded=False,\n",
    "        get_hexagon=\"H3\",\n",
    "        get_fill_color=[\"R\",\"G\",\"B\"],\n",
    "        line_width_min_pixels=0,\n",
    "        opacity=0.4)\n",
    "\n",
    "tooltip = {\n",
    "   \"html\": \"\"\"<b>H3:</b> {H3} <br> <b>Count:</b> {COUNT}\"\"\",\n",
    "   \"style\": {\n",
    "       \"width\":\"50%\",\n",
    "        \"backgroundColor\": \"steelblue\",\n",
    "        \"color\": \"white\",\n",
    "       \"text-wrap\": \"balance\"\n",
    "   }\n",
    "}\n",
    "\n",
    "st.pydeck_chart(pdk.Deck(\n",
    "    map_style=None,\n",
    "    initial_view_state=pdk.ViewState(\n",
    "        latitude=LAT,\n",
    "        longitude=LON,\n",
    "        zoom=5,\n",
    "        height=600\n",
    "        ),\n",
    "    \n",
    "layers= [h3], tooltip = tooltip\n",
    "\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9948ecf-e336-4459-8c2a-3c14095c392e",
   "metadata": {
    "collapsed": false,
    "name": "h_data_transformations"
   },
   "source": [
    "# 5. Search and filter on GEOHASH \n",
    "\n",
    "Now the focus it turned to the world wide open source buildings dataset provided by Carto.  In order to avoid whole table scanning, the dataset will be pruned in advance to only cover the United Kingdom.  Filtering by geohash is a very simple way to filter large geographic datasets.  A geohash is a way of encoding geographic coordinates (latitude and longitude) into a short string of letters and digits. It is useful for spatial indexing, location-based searches, and geographic data compression. You can view [this webpage](https://www.movable-type.co.uk/scripts/geohash.html) to search for valid geohashes.  As this is a large dataset, a larger warehouse is used.  Once pruned, the results are joined to the built up extents dataset. This will effectively 'geocode' the buildings to a town which can then be used later for filtering purposes.  \n",
    "\n",
    "This may take a couple of minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98570d58-afde-44c5-b4e4-cdc83e321874",
   "metadata": {
    "language": "sql",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE WAREHOUSE XX_LARGE_HEAVY_LIFT\n",
    "WITH \n",
    "  WAREHOUSE_SIZE = '2X-LARGE'\n",
    "  AUTO_SUSPEND = 60\n",
    "  AUTO_RESUME = TRUE\n",
    "  INITIALLY_SUSPENDED = TRUE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29be0f4b-834d-4431-944f-ff4836c04fb6",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "create_table_buildings"
   },
   "outputs": [],
   "source": [
    "USE WAREHOUSE XX_LARGE_HEAVY_LIFT;\n",
    "CREATE OR REPLACE TABLE DEFAULT_SCHEMA.BUILDINGS AS \n",
    "\n",
    "SELECT A.*,B.NAME1_TEXT FROM\n",
    "\n",
    "(SELECT *,ST_GEOHASH(GEOMETRY,2) GEOHASH FROM OVERTURE_MAPS__BUILDINGS.CARTO.BUILDING WHERE GEOHASH IN('gf','gb''gc','u1')) A\n",
    "\n",
    "INNER JOIN\n",
    "\n",
    "URBAN_EXTENTS_FOR_CITIES_TOWNS_AND_VILLAGES__GREAT_BRITAIN_OPEN_BUILT_UP_AREAS.PRS_OPEN_BUILT_UP_AREAS_SCH.PRS_OPEN_BUILT_UP_EXTENTS_TBL B\n",
    "\n",
    "ON\n",
    "\n",
    "ST_INTERSECTS(A.GEOMETRY,B.GEOGRAPHY) \n",
    "\n",
    "ORDER BY NAME1_TEXT\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ";\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ALTER WAREHOUSE XX_LARGE_HEAVY_LIFT SUSPEND;\n",
    "\n",
    "USE WAREHOUSE DEFAULT_WH;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5528c1-1340-4006-944c-06bcbb9460e2",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "Add_search_optimisation_on_buildings"
   },
   "outputs": [],
   "source": [
    "ALTER TABLE DEFAULT_SCHEMA.BUILDINGS ADD SEARCH OPTIMIZATION ON GEO(GEOMETRY);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fd266e-0966-41bd-9a57-d0511acea073",
   "metadata": {
    "collapsed": false,
    "name": "add_uprn_details"
   },
   "source": [
    "As we have building data, let's attach each building to it's unique property reference number (UPRN).  This can be achieved simply by joining to the UPRN dataset which was imported at the beginning of the lab. The **ST_INTERECTS** join will work well for this.  To avoid confusion, **GEOGRAPHY** (from the UPRN table) has been renamed to **POINTS**.\n",
    "\n",
    "In the SQL below, a **RIGHT JOIN** is used.  This ensures that all buildings are viewable despite whether or not a UPRN exists.  However, as all properties have a UPRN in the UK, this is extremely unlikely.  However, what will happen for some buildings - is that multiple UPRNS will be discovered on a single building.  The handling of this effect will be solved later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564080af-0180-4af3-ac4d-a7ef41e1a7e4",
   "metadata": {
    "language": "sql",
    "name": "buildings_with_uprn"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE DEFAULT_SCHEMA.BUILDINGS_WITH_UPRN AS\n",
    "\n",
    "SELECT * RENAME (GEOGRAPHY AS POINT)\n",
    "\n",
    "FROM UNIQUE_PROPERTY_REFERENCE_NUMBERS__GREAT_BRITAIN_OPEN_UPRN.PRS_OPEN_UPRN_SCH.PRS_OPEN_UPRN_TBL A  \n",
    "\n",
    "RIGHT JOIN DEFAULT_SCHEMA.BUILDINGS B\n",
    "\n",
    "ON ST_INTERSECTS(A.GEOGRAPHY,B.GEOMETRY);\n",
    "\n",
    "ALTER TABLE DEFAULT_SCHEMA.BUILDINGS ADD SEARCH OPTIMIZATION ON GEO(GEOMETRY);\n",
    "\n",
    "SELECT * FROM DEFAULT_SCHEMA.BUILDINGS_WITH_UPRN LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebddbed-1beb-4876-9771-d54404c4d005",
   "metadata": {
    "collapsed": false,
    "name": "h_render_results"
   },
   "source": [
    "Finally, the results are rendered in the Streamlit below. Similarly to previous examples, the town extents are used to filter the building polygons.  This time, one big polygon filters lots of smaller polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4a5374-e72d-4169-8053-315a17683062",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "filter_buildings"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pydeck as pdk\n",
    "import json\n",
    "session = get_active_session()\n",
    "from snowflake.snowpark.functions import *\n",
    "\n",
    "tooltip = {\n",
    "   \"html\": \"\"\"<b>CLASS:</b> {CLASS} <br> <b>SUBTYPE:</b> {SUBTYPE} <br> <b>UPRN:</b> {UPRN}\"\"\",\n",
    "   \"style\": {\n",
    "       \"width\":\"50%\",\n",
    "        \"backgroundColor\": \"steelblue\",\n",
    "        \"color\": \"white\",\n",
    "       \"text-wrap\": \"balance\"\n",
    "   }\n",
    "}\n",
    "BUILDINGS = session.table('DEFAULT_SCHEMA.BUILDINGS_WITH_UPRN')\n",
    "filter = BUILDINGS.select('NAME1_TEXT').distinct()\n",
    "filter = st.selectbox('Choose Town:',filter, 6)\n",
    "\n",
    "BUILDINGS = BUILDINGS.filter(col('NAME1_TEXT')==filter).group_by('ID','CLASS','SUBTYPE').agg(any_value('GEOMETRY').alias('GEOMETRY')\n",
    "                                                                                             ,array_to_string(array_agg('UPRN'),lit(', ')).alias('UPRN'))\n",
    "\n",
    "centre = session.table('URBAN_EXTENTS_FOR_CITIES_TOWNS_AND_VILLAGES__GREAT_BRITAIN_OPEN_BUILT_UP_AREAS.PRS_OPEN_BUILT_UP_AREAS_SCH.PRS_OPEN_BUILT_UP_EXTENTS_TBL')\n",
    "centre = centre.filter(col('NAME1_TEXT')==filter)\n",
    "centre = centre.with_column('CENTROID',call_function('ST_CENTROID',col('GEOGRAPHY')))\n",
    "centre = centre.with_column('LON',call_function('ST_X',col('CENTROID')))\n",
    "centre = centre.with_column('LAT',call_function('ST_Y',col('CENTROID')))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "centrepd = centre.select('LON','LAT').to_pandas()\n",
    "LON = centrepd.LON.iloc[0]\n",
    "LAT = centrepd.LAT.iloc[0]\n",
    "# Populate dataframe from query\n",
    "\n",
    "datapd = BUILDINGS.to_pandas()\n",
    "\n",
    "datapd[\"coordinates\"] = datapd[\"GEOMETRY\"].apply(lambda row: json.loads(row)[\"coordinates\"])\n",
    "\n",
    "st.write('Buildings in a town')\n",
    "\n",
    "# Create data layer - this where the geometry is likely failing - column is now called geometry to match geopandas default\n",
    "data_layer = pdk.Layer(\n",
    "    \"PolygonLayer\",\n",
    "    datapd,\n",
    "    opacity=0.8,\n",
    "    get_polygon=\"coordinates\", \n",
    "    filled=True,\n",
    "    get_fill_color=[41, 181, 232],\n",
    "    get_line_color=[0, 0, 0],\n",
    "    auto_highlight=True,\n",
    "    pickable=True,\n",
    ")\n",
    "\n",
    "# Set the view on the map\n",
    "view_state = pdk.ViewState(\n",
    "    longitude=LON,\n",
    "    latitude=LAT,\n",
    "    zoom=13,  # Adjust zoom if needed\n",
    "    pitch=0,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Render the map with layer and tooltip\n",
    "r = pdk.Deck(\n",
    "    layers=[data_layer],\n",
    "    initial_view_state=view_state,\n",
    "    map_style=None,\n",
    "    tooltip=tooltip)\n",
    "    \n",
    "st.pydeck_chart(r, use_container_width=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106fe54f-2174-4132-9cde-73249b421aae",
   "metadata": {
    "collapsed": false,
    "name": "Conclusion"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "You have now completed a hands on lab which explores how you can use snowflake's geospatial capabilities to visualise location data using Streamlit inside a Snowflake Powered Notebook.\n",
    "\n",
    "### We have Covered examples of the following:\n",
    "\n",
    "- Data Formats, Geo Data Types\n",
    "- Points, Linestrings, Polygons\n",
    "- H3\n",
    "- Visualising data with Streamlit and Pydeck\n",
    "- Spatial Joins and calculations\n",
    "- Search optimisation\n",
    "- Geohash\n",
    "\n",
    "### Streamlit Example\n",
    "\n",
    "- Navigate back to the home page and open **Projects>>Streamlit**.\n",
    "\n",
    "- Open the **ROAD_NETWORK** Streamlit example which combines points, linestrings and polygons together to illustrate blueprints of towns.  This will also give a starting point to create many other streamlit examples for a variety of usecases.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "becky.oconnor@snowflake.com",
   "authorId": "4332297057182",
   "authorName": "USER",
   "lastEditTime": 1741963930346,
   "notebookId": "npcpkcwkuqryb2xavjxw",
   "sessionId": "bebacda8-5def-422c-b412-7fc45a229b75"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
